---
layout: post
title:  'Sqoop 常用操作'
date:   2018-12-13
tags: sqoop 
categories: [大数据框架,sqoop]
---



## Sqoop常用命令



### 1.预备环境

- Hadoop
- Zookeeper
- MySql
- Hive
- HBase

or

- CDH

### 2. import

#### 简介

该工具可以将单个关系型数据库的表导入到HDFS上

#### 常用参数

| 参数名称 | 功能                                                         |
| ------------------------------------ | ------------------------------------------------------------ |
| `--connect <jdbc-uri>`               | jdbc链接(例：`jdbc:mysql://host_name/table_name`)            |
| `--help`                             | 帮助                                                         |
| `--password <password>`              | 密码                                                         |
| `--username <username> `              | 账号|
| `--direct`		| import工具将会使用JDBC提供的高性能工具例如MySql中的mysqldump） |
| `--fields-terminated-by <char>`	| 设置导出内容不同列的分隔符（默认 ','） |
| `--delete-target-dir`	| 如果文件已经存在则删除 |
| `--target-dir <dir>`	| 指定目录输出 |
|`last-value` | 上次导出的主键（增量导出时使用） |

```shell
sqoop import --connect jdbc:mysql://nhadoop1/test_user \
--username root \
--password 123456 \
--table user \
--direct \
--num-mappers 1 \
--fields-terminated-by ,\
--delete-target-dir
```



#### 导入到Hive

|参数 | 功能 |
| --------------- | -------------- |
| `--hive-import` | 指定导入到hive |
| `--hive-database <database-name>` | 指定导入到数据库 |
| `--hive-table <table-name>` | 指定导入的表 |

```shell
sqoop import --connect jdbc:mysql://nhadoop1/test_user \
--username root \
--password 123456 \
--table user \
--direct \
--num-mappers 1 \
--fields-terminated-by , \
--delete-target-dir
--hive-import \
--hive-database database-name \
--hive-table table-name
```

*原生环境可能存在的坑*

1. java.lang.ClassNotFoundException

Sqoop 的lib中缺少Hive 的jar包，从Hive 中找的缺少的jar包到Sqoop中即可

2. 缺少配置文件

拷贝hive/conf/hive-site.xml到sqoop/conf下

### export

| 参数                                   | 功能`                                                       |
| -------------------------------------- | ----------------------------------------------------------- |
| `--export-dir`                         | 指定输出目录                                                |
| `-- input-fields-terminated-by <char>` | 指定文件每行的分隔符                                        |
| `--update-key`                         | 使用update进行输出（默认insert），后面接匹配的键（例如 ID） |
| `--columns <col,col,col…> `            | 指定输出的栏目名                                            |

```shell
# 更新操作
sqoop export --connect jdbc:mysql://nhadoop1/test_user \
--username root \
--password 123456 \
--table jobs_k \
--columns rowkey,salary \
--export-dir /user/hive/warehouse/test.db/hbase_map_p \
--input-fields-terminated-by '\001' \
--update-key rowkey
```



### 补充

#### 1. 执行文件中的命令

```shell
# 原语句
$ sqoop import --connect jdbc:mysql://localhost/db --username foo --table TEST

# 执行文件中的语句
$ sqoop --options-file /users/homer/work/import.txt --table TEST

# 文件中的内容
import
--connect
jdbc:mysql://localhost/db
--username
foo
```

